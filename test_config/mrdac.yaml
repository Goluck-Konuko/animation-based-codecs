dataset_params:
  train_dir: ../datasets/VoxCeleb/train
  test_dir: ../datasets/VoxCeleb/test
  cpk_path: 'checkpoints/mrdac.pth.tar' #path to checkpoint to resume training
  frame_shape: [256, 256, 3] #Video frame dimensions
  num_sources: 4 #Number of frames per video sample in batch [Num. of references = num_sources-1]
  target_delta: 1 #Minimum spacing between frames if num_sources>2
  augmentation_params:
    flip_param:
      horizontal_flip: False 
      time_flip: False
    jitter_param:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.1

model_params:
  common_params:
    num_kp: 10 #Number of motion keypoints
    num_channels: 3
  kp_detector_params:
    temperature: 0.1
    block_expansion: 32
    max_features: 1024
    scale_factor: 0.25
    num_blocks: 5
    quantize: False #Set to True for training
  generator_params:
    block_expansion: 64
    max_features: 512
    num_down_blocks: 2
    num_bottleneck_blocks: 6
    estimate_occlusion_map: True
    use_ref_weights: True
    use_contrastive_loss: True
    ref_coder: True
    dense_motion_params:
      block_expansion: 64
      max_features: 1024
      num_blocks: 5
      scale_factor: 0.25
    iframe_params:
      variable_bitrate: True
      levels: 7
      scale_factor: 1
      input_resolution: [256,256]
  discriminator_params:
    scales: [1]
    block_expansion: 32
    max_features: 512
    num_blocks: 4
    use_kp: True
    disc_type: 'multi_scale'

train_params:
  num_epochs: 100
  num_repeats: 1
  epoch_milestones: []
  lr : 2.0e-4
  batch_size: 2
  scales: [1, 0.5, 0.25, 0.125]
  checkpoint_freq: 1
  transform_params:
    sigma_affine: 0.05
    sigma_tps: 0.005
    points_tps: 5
  loss_weights:
    generator_gan: 1
    discriminator_gan: 1
    feature_matching: [10, 10, 10, 10]
    perceptual: [10, 10, 10, 10, 10]
    equivariance_value: 10
    mse_loss: 0
    contrastive_loss: 0.00001

reconstruction_params:
  num_videos: 1000
  format: ".mp4"

animate_params:
  num_pairs: 50
  format: ".mp4"
  normalization_params:
    adapt_movement_scale: False
    use_relative_movement: True
    use_relative_jacobian: True

visualizer_params:
  kp_size: 5
  draw_border: True
  colormap: "gist_rainbow"

eval_params:
  qp: 6 #QPS [1-6] #coding quality for the reference frames.
  metrics: ['lpips','ms_ssim','dists','msVGG', 'fsim', 'psnr','vmaf']
  num_frames: 250
  gop_size: 25 #[25,50,100,250] will determine the total number of reference frames used
  num_references: 4 # number of reference frames used per target
  use_ref_weights: True # compute an weight vector based on the proximity of each reference to a given target
  reference_sampling: 'uniform' #'coarse2fine' #Reference frame selection strategy
  search_window: 5 #when using coarse to fine-> search for best candidate within [-n:n] around the random sampling point
  coding_mode: 2 #coding modes [0 - animate with 1 reference, 1 - progressive update of references, 2 - low delay bi-directional]
  fps: 25
  per_frame_metrics: False
